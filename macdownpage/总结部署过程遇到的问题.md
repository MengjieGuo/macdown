# 总结部署过程遇到的问题

## 部署过程分为3步
### 1本地主机测试要求
> 开发人员在本地调试通过之后，就可以把代码push到coding上面进行审核、合并。

### 2线下测试部署要求
> 线下测试也是很重要的，是对线上环境的一个模拟，使用docker启动wx_fine项目，从redis取数据；使用docker启动auto_fetch从postgres取数据。经过本地测试的代码一定要经过线下测试，不然绝对不要部署在线上再测试。
> 

### 3 线上部署要求
> 1. 对于wx_fine，每次部署前需要测试项目代码是否正确运行，可以重命名项目，然后修改docker-compose.yml的端口信息，启动正常后就进入正式部署阶段，时间为5分钟。
> 
> 2. 首先到209机器上面修改D:\BaiduNetdiskDownload\nginx-1.12.0\conf\目录下的nginx.con，注意复制一份最为备份。把rewrite ^(.*) http://auth.jtgzfw.com/wx_fine/50x.html break;的注释去掉，保存修改，到windows服务管理里面重新启动nginx转发服务。

```
 #gzip  on;
    server {
		listen 80;
		server_name wxapp.jtgzfw.com;
		# rewrite ^(.*) http://auth.jtgzfw.com/wx_fine/50x.html break;
		location / {
            proxy_pass http://172.16.0.21:8000;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
			proxy_set_header Cookie $http_cookie;
			#proxy_intercept_errors on;
		}
	}
```	
> 1. 停止之前在docker中运行的wx_fine:v01的容器，docker stop $(docker ps -a -q)这条命令会停止所有正在运行的容器。
> 
> 2. 运行docker-compose run web python manage.py makemigrations docker-compose run web python manage.py migrate
> 
> 3. 启动新的wx_fine:v0.2的容器，docker-compose up。
> 

## 线上部署遇到的问题
```
部署代码要经过线下测试，但是本次部署前只线下测试了auto-fetch代码，对于wx_fine代码也需要在线下进行测试部署。
```
### 1 wx_fine项目部署
> 在21机器上面，昨天没有经过步骤2就直接从coding上面下载代码，然后进行部署。遇到的问题：
> 
> 1. 新的代码需要更新镜像，在本地制作完成后进行测试，在线下进行测试，上传线上部署。
> 
> 2. 关于配置文件的问题，配置文件需要3份，一份本地主机，一份线下测试，一份线上的配置。但是之前没有在线上部署的经验，所以当需要修改配置文件时，不知道需要修改配置文件的哪些地方。经过部署流程后，可以写出三份配置文件。
> 
> 3. 下载下来的代码没有经过测试就直接push到coding，代码没有经过review。经过测试通过的代码需要打tag，部署代码时直接从tag下载代码进行部署。

### 2 auto_fetch项目
> auto_fetch需要部署在两台机器上面，经过线下部署测试后传递代码到服务器上面。遇到的问题：

#### 2.1 没有正确理解配置文件的各个部分的作用，对于外网主机198。
>
> 对于docker-compose.yml。

```
version: '2.1'
services:
  db:
    image: rabbitmq:3-management
    hostname: rabbit
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
    ports:
      - "5672:5672"
      - "15672:15672"
  redis:
    image: redis:latest
    hostname: redis
    volumes:
      - /var/redis:/data	* 这里需要修改，挂载的目录需要根据服务器的目录大小进行修改，通过命令 `df -h`查看磁盘使用情况。这里使用/var/redis:/data*
    ports:
      - "6399:6379"			* 这里的端口需要修改，因为服务器上面已经运行了一个redis，把端口6379占用了，所以现在使用6399，线上现在使用的是6378。
  nginx:
    image: nginx:latest
    ports:
      - "8001:8000"			* 这里需要修改，服务器上面存在使用端口8000的nginx，需要使用其他端口，这里使用8001。
    volumes:
 #    - ./lightGateway/static/:/user/share/nginx/html/:ro
      - ./lightGateway/static/:/static/:ro
      - ./lightGateway/deploy/nginx/lightGateway.conf:/etc/nginx/conf.d/my.conf
    depends_on:
      - web
    links:
      - web:weblocal
  web:
    image: lightweb:v0.2	* 这里需要修改，注意当更新镜像时，这里需要修改版本号。
    command: circusd lightGateway/deploy/circusd.ini
    hostname: weblocal
    volumes:
      - .:/code
      - ./lightGateway/static:/static
      - /home/newlight/request/:/home/newlight/request/
      - /home/newlight/response/:/home/newlight/response/
    ports:
      - "8000"
    links:
      - db:rabbit
      - redis:redis
    environment:
      - LANG=C.UTF-8
    # - DJANGO_SETTINGS_MODULE=lightGateway.settings.develop
    depends_on:
      - redis
  # Celery worker
  worker:
    image: lightweb:v0.2
  # command: bash -c " && celery -A lightGateway beat -l info -S django"
    command: circusd lightGateway/deploy/celery-circusd.ini
    volumes:
      - .:/code
      - /home/newlight/request/:/home/newlight/request/
      - /home/newlight/response/:/home/newlight/response/
    links:
      - db:rabbit
      - web:weblocal
    depends_on:
      - db
      - web
```

> 对于setting.py文件，这里在celery.py配置使用production.py文件。

```
# 这几个都需要修改，分别代表是内网主机的request目录，内网主机的response目录，外网主机的requst目录，外网主机的response目录。
NNER_REQUEST = "/home/newlight/request/"
INNER_RESPONSE = "/home/newlight/response/"
OUTER_REQUUEST = "/home/newlight/request/"
OUTER_RESPONSE = "/home/newlight/response/"


# redis信息 ，如果用docker,请注意HOST请注意HOST名字的写法名字的写法，这个redis是auto_fetch写违法信息，机动车等信息的地方。
REDIS_HOST = ‘125.46.83.198’#'redis'	* 这里需要修改，ip为外网主机198的ip
REDIS_PORT = 6378						* 这里需要修改，端口为docker-compose.yml配置的端口，这里是6378
REDIS_DB = 0

# ORACLE数据库信息，内网需要修改，这里不需要修改这5条信息，因为不会使用到。
ORACLE_HOST = "192.168.1.110"
ORACLE_PORT = "1521"
ORACLE_SERVICE_NAME= "zzlhy"
ORACLE_USER = "trff_app"
ORACLE_PASSWORD = "trff_admin"

GET_ORACLE_INFO_STRATEGY = CACHE_ALL_ILLEGAL_INFO


# 缓存前缀信息，为了区分存入redis的信息，而加入的前缀。
REDIS_CAR_PREFIX = 'C'
REDIS_DL_PREFIX = 'D'
REDIS_WFXW_PREFIX = 'W'

# 平台用户数据库信息，需要从wx_fine项目所在主机的postgres数据库取平台用户的信息。这里是postgres的连接信息。
PINGTAI_HOST='172.16.0.21'#'192.168.1.179‘	* 这个是postgres所在主机ip，这里是21的主机ip。
PINGTAI_PORT = '5432'				* postgres端口，当修改时请于docker-compose.yml文件保持一致。
PINGTAI_DB = 'wxfine'				* postgres中，数据库名称。
PINGTAI_USER = "postgres"			* postgres数据库的用户名。
PINGTAI_PASSWORD = "postgres.lkj"	* postgresl数据库的用户密码。
```
> 对于celery.py。

```
# set the default Django settings module for the 'celery' program.
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'lightGateway.settings.production')
									* 需要修改，这个配置使用那个setting文件，这里配置使用production.py配置文件
app = Celery('lightGateway')
# Using a string here means the worker don't have to serialize
# the configuration object to child processes.
# - namespace='CELERY' means all celery-related configuration keys
#   should have a `CELERY_` prefix.
app.config_from_object('django.conf:settings', namespace='CELERY')
from django.conf import settings
# Load task modules from all registered Django app configs.
app.autodiscover_tasks()

@app.task(bind=False)
def debug_task(self):
    print('Request: {0!r}'.format(self.request))


@app.on_after_finalize.connect
def auto_receive_file(sender, **kwargs):
    sender.add_periodic_task(2.0, find_file_to_http.s(settings.OUTER_RESPONSE), name='清理文件')
    								* 需要修改监视的目录，这里监视外网主机的resposne目录，当有违法信息、车辆信息等从内网返回，就把信息写入redis数据库。
    sender.add_periodic_task(5.0, get_users_driverlicense_car_info.s(), name='定时获取平台需要获取车辆信息的用户')
    								* 需要去掉注释，负责从postgres获取平台用户信息，以供内网机器取违法、驾驶证等信息。 
    # sender.add_periodic_task(crontab(hour=23, minute=30), get_users_info.s(),name='定时触发获取违法信息')
    								* 需要加注释，这个定时任务是为内网机器写的。
    # sender.add_periodic_task(5.0, get_users_info.s(), name='定时触发获取违法信息')
    # 每次停机开机后，自动拉取最新的cache信息
    # 不能再这里执行自动拉取信息，可手动执行脚本触发，因为我们每次启动多个django应用，如果在这里启动，会导致重复执行。
    # 脚本非常简单的，只需要在对应的目录下，创建一个 XX.user.pickle的文件即可。touch 命令就可以。
```

#### 2.2 对于内网主机23。
> 对于docker-compose.yml

> 对于setting.py，因为是线上在celery.py指定使用production.py

> 对于celery.py
